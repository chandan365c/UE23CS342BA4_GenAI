{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INSTALL DEPENDENCIES"
      ],
      "metadata": {
        "id": "p6lI-eGE0-G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkqDdAZ6yU_W",
        "outputId": "5283028b-17c7-41b5-aa10-3ceb51874cf5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "wSTstZ2gytP-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Key Setup"
      ],
      "metadata": {
        "id": "QN7of2Sj1oHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# Prompt user for API key if not already set\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your GROQ API Key: \")\n",
        "\n",
        "# Initialize Groq client\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "print(\"Groq client initialized successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KKvzvpbyv_p",
        "outputId": "3745e57a-2434-4592-d5d9-1ee6d3b86e59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your GROQ API Key: ··········\n",
            "Groq client initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Expert Configurations"
      ],
      "metadata": {
        "id": "zh1azvEH1qWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    \"technical\": {\n",
        "        \"system_prompt\": \"\"\"You are a Technical Support Expert.\n",
        "Be precise, rigorous, and code-focused.\n",
        "Provide clear debugging steps and example fixes.\n",
        "Avoid unnecessary conversation.\n",
        "\"\"\"\n",
        "    },\n",
        "    \"billing\": {\n",
        "        \"system_prompt\": \"\"\"You are a Billing Support Specialist.\n",
        "Be empathetic, professional, and policy-driven.\n",
        "Focus on charges, refunds, subscriptions, and invoices.\n",
        "Provide clear next steps for resolution.\n",
        "\"\"\"\n",
        "    },\n",
        "    \"general\": {\n",
        "        \"system_prompt\": \"\"\"You are a helpful customer support assistant.\n",
        "Handle general questions and casual conversation politely.\n",
        "\"\"\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "uO3xf07rzMrf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Router Logic"
      ],
      "metadata": {
        "id": "5O0WWVBl1uh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_prompt(user_input):\n",
        "    router_prompt = f\"\"\"\n",
        "Classify the following user request into one of these categories:\n",
        "[technical, billing, general]\n",
        "\n",
        "Return ONLY the category name. No explanation.\n",
        "\n",
        "User request:\n",
        "{user_input}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a strict intent classifier.\"},\n",
        "            {\"role\": \"user\", \"content\": router_prompt}\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    category = response.choices[0].message.content.strip().lower()\n",
        "    return category"
      ],
      "metadata": {
        "id": "9IcJwK6mzShh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Orchestrator Logic"
      ],
      "metadata": {
        "id": "_jYrls7x1zhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_request(user_input):\n",
        "\n",
        "    # Step 1: Route\n",
        "    category = route_prompt(user_input)\n",
        "    print(f\"Routed to: {category}\")\n",
        "\n",
        "    # Fallback safety\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    system_prompt = MODEL_CONFIG[category][\"system_prompt\"]\n",
        "\n",
        "    # Step 2: Call Expert\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "RDyaJHZVzT5I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User End Point"
      ],
      "metadata": {
        "id": "40-8O1ux15lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = input(\"Enter your customer support request: \")\n",
        "response = process_request(user_query)\n",
        "\n",
        "print(\"\\nFinal Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGXkgxydzcda",
        "outputId": "469be09f-86fb-42a3-cb7c-d71fdec7c027"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your customer support request: I was charged twice for my subscription this month.\n",
            "Routed to: billing\n",
            "\n",
            "Final Response:\n",
            "\n",
            "I'm so sorry to hear that you were charged twice for your subscription this month. I can imagine how frustrating that must be for you. I'm here to help resolve this issue as quickly as possible.\n",
            "\n",
            "To get started, could you please provide me with your subscription details, including your account name and the date of the duplicate charge? This will help me locate your account and investigate the issue further.\n",
            "\n",
            "Additionally, I'll need to verify some information to ensure that I'm assisting the correct account holder. Please confirm your email address associated with the subscription and the last 4 digits of the payment method used for the subscription.\n",
            "\n",
            "Once I have this information, I'll be happy to review your account and work with you to process a refund for the duplicate charge. If the duplicate charge was an error on our part, we'll also take steps to prevent this from happening again in the future.\n",
            "\n",
            "Please let me know if you have any questions or concerns, and I'll do my best to address them. Your satisfaction is my top priority, and I appreciate your patience and cooperation as we work to resolve this issue.\n"
          ]
        }
      ]
    }
  ]
}